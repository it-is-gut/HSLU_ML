{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "# silence future deprecation warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regularization for Linear Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although linear regression is a linear machine learning method, you can have nonlinear dependencies if you transform some of the independent variables by a nonlinear function. By doing this, you can improve the fit of your method. Let us demonstrate this on a house price dataset from [Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction). Note that this dataset is not identical with one you used in the linear regression exercise, since the this dataset is too small and would cause unreliable evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to have a simple linear regression problem with only one independent variable. Thus, we only keep *price* and *sqft_living*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sqft_living\n",
       "0  221900.0         1180\n",
       "1  538000.0         2570\n",
       "2  180000.0          770\n",
       "3  604000.0         1960\n",
       "4  510000.0         1680"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"price\",\"sqft_living\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data\n",
    "Let us normalize the data by using *min-max normalization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.117092</td>\n",
       "      <td>0.263499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>0.151895</td>\n",
       "      <td>0.269978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18621</th>\n",
       "      <td>0.095222</td>\n",
       "      <td>0.223542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0.082309</td>\n",
       "      <td>0.063715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026</th>\n",
       "      <td>0.090590</td>\n",
       "      <td>0.184665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  sqft_living\n",
       "493    0.117092     0.263499\n",
       "4253   0.151895     0.269978\n",
       "18621  0.095222     0.223542\n",
       "1463   0.082309     0.063715\n",
       "12026  0.090590     0.184665"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "test = pd.DataFrame(scaler.transform(test), columns=test.columns, index=test.index)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"sqft_living\"]]\n",
    "y_train = train[[\"price\"]]\n",
    "\n",
    "X_test = test[[\"sqft_living\"]]\n",
    "y_test = test[[\"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias term\n",
    "To account for the bias term, we add a column containing only ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>sqft_living</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>0.263499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>1</td>\n",
       "      <td>0.269978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18621</th>\n",
       "      <td>1</td>\n",
       "      <td>0.223542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>1</td>\n",
       "      <td>0.063715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12026</th>\n",
       "      <td>1</td>\n",
       "      <td>0.184665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  sqft_living\n",
       "493       1     0.263499\n",
       "4253      1     0.269978\n",
       "18621     1     0.223542\n",
       "1463      1     0.063715\n",
       "12026     1     0.184665"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"bias\"] = 1\n",
    "X_test[\"bias\"] = 1\n",
    "\n",
    "# Force order\n",
    "X_train = X_train[[\"bias\", \"sqft_living\"]]\n",
    "X_test = X_test[[\"bias\", \"sqft_living\"]]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a linear regression model\n",
    "Define a linear regression function to estimate the parameters $\\theta$ based on the normal equation:\n",
    "  \n",
    "  $\\Theta:=(X^{\\top}X)^{-1}(X^{\\top}y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    thetas = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    thetas = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = fit(X_train, y_train)\n",
    "\n",
    "expected_thetas = np.array([[7.39560812e-05], [4.94185750e-01]])\n",
    "np.testing.assert_array_almost_equal(thetas, expected_thetas, decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict prices\n",
    "Using $X$ and the estimated $\\theta$, predict the house prices on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def predict(X, thetas):\n",
    "    y_pred = np.dot(X, thetas)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def predict(X, thetas):\n",
    "    y_pred = np.dot(X, thetas)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30291368e-01],\n",
       "       [1.33493435e-01],\n",
       "       [1.10545285e-01],\n",
       "       ...,\n",
       "       [9.29339134e-02],\n",
       "       [7.39560812e-05],\n",
       "       [1.46835383e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(X_train, thetas)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions\n",
    "Let us plot house prices and predicted house prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_line(X, thetas, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    deg = len(thetas)-1\n",
    "    poly = PolynomialFeatures(deg)\n",
    "    \n",
    "    xs = np.arange(X.min(), X.max()+0.1, 0.01).reshape(-1,1)\n",
    "    x = poly.fit_transform(xs)\n",
    "    y_pred = np.dot(x, thetas)\n",
    "    \n",
    "    ax.plot(xs, y_pred, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X_train[\"sqft_living\"].values, y_train.values, \"bo\", markersize=1)\n",
    "plot_regression_line(X_train[\"sqft_living\"].values, thetas, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate model performance\n",
    "Now let's check how good our model performs by calculating the $R^2$ score on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price    0.492342\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(X_test, thetas)\n",
    "r2 = 1 - (np.sum((y_test-y_pred_test)**2) / np.sum((y_test-y_pred_test.mean())**2))\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.49226256935760815\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(X_test, thetas)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2: \",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to improve the fit by adding $x^2$ as additional independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_living^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>1</td>\n",
       "      <td>0.182505</td>\n",
       "      <td>0.033308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>1</td>\n",
       "      <td>0.272138</td>\n",
       "      <td>0.074059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366091</td>\n",
       "      <td>0.134022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218</th>\n",
       "      <td>1</td>\n",
       "      <td>0.451404</td>\n",
       "      <td>0.203765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>1</td>\n",
       "      <td>0.234341</td>\n",
       "      <td>0.054916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias  sqft_living  sqft_living^2\n",
       "735       1     0.182505       0.033308\n",
       "2830      1     0.272138       0.074059\n",
       "4106      1     0.366091       0.134022\n",
       "16218     1     0.451404       0.203765\n",
       "19964     1     0.234341       0.054916"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_deg2 = X_train.copy()\n",
    "X_train_deg2[\"sqft_living^2\"] = X_train_deg2[\"sqft_living\"] * X_train_deg2[\"sqft_living\"]\n",
    "\n",
    "X_test_deg2 = X_test.copy()\n",
    "X_test_deg2[\"sqft_living^2\"] = X_test_deg2[\"sqft_living\"] * X_test_deg2[\"sqft_living\"]\n",
    "X_test_deg2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model with the additonal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas_deg2 = fit(X_train_deg2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price    0.538089\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(X_test_deg2, thetas_deg2)\n",
    "r2 = 1 - (np.sum((y_test-y_pred_test)**2) / np.sum((y_test-y_pred_test.mean())**2))\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "y_pred_test = predict(X_test_deg2, thetas_deg2)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "print(\"R2: \",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, by adding $x^2$ as additional independent variable we could slightly improve our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try if we can further improve our performance by adding more polynomial features. To generate our polynomial features we will use the Scikit-Learn function [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28935147a9a4efc801dadaca56b80b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='poly_deg', max=18, min=1), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(poly_deg =(1,18,1))\n",
    "def f(poly_deg=1):\n",
    "    poly = PolynomialFeatures(poly_deg)\n",
    "    X_train_deg = poly.fit_transform(X_train[\"sqft_living\"].values.reshape(-1,1))\n",
    "    X_test_deg = poly.fit_transform(X_test[\"sqft_living\"].values.reshape(-1,1))\n",
    "\n",
    "    thetas_deg = fit(X_train_deg, y_train)\n",
    "    \n",
    "    y_pred_test = predict(X_test_deg, thetas_deg)\n",
    "    y_pred_train = predict(X_train_deg, thetas_deg)\n",
    "    \n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    print(\"R2 Train {0:.5f}\".format(r2_train))\n",
    "    print(\"R2 Test {0:.5f}\".format(r2_test))\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20,10))\n",
    "    ax0.set_title(\"Training data - polynomial degree {}\".format(poly_deg))\n",
    "    ax0.plot(X_train[\"sqft_living\"], y_train[\"price\"], \"bo\", markersize=1)\n",
    "    plot_regression_line(X_train_deg, thetas_deg, ax0)\n",
    "    \n",
    "    ax1.set_title(\"Test data - polynomial degree {}\".format(poly_deg))\n",
    "    ax1.plot(X_test[\"sqft_living\"], y_test[\"price\"], \"bo\", markersize=1)\n",
    "    plot_regression_line(X_test_deg, thetas_deg, ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you recognize when you increase the polynomial degree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Answer the question on ILIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effect of overfitting can be reduced by regularization. Implement the regularized version of linear regression: $\\Theta:=(X^{\\top}X+\\lambda \\begin{bmatrix}\n",
    "    0  & 0 &\\ldots&0 \\\\\n",
    "    0 & 1 & \\\\\n",
    "    \\ldots & & \\ddots & \\\\\n",
    "    0& & & 1\n",
    "  \\end{bmatrix} )^{-1}(X^{\\top}y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def fit_reg(X, y, lam):\n",
    "    thetas = np.linalg.inv(X.T.dot(X)+(lam * np.identity((X.T.dot(X)).shape[0]))).dot(X.T).dot(y)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "def fit_reg(X, y, lam):\n",
    "    Xt = np.transpose(X)\n",
    "    XtX = np.dot(Xt,X)\n",
    "    XtX = XtX + (lam * np.identity(XtX.shape[0]))\n",
    "    XtXm1 = np.linalg.inv(XtX)\n",
    "    Xty = np.dot(Xt,y)\n",
    "    thetas = np.dot(XtXm1,Xty)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your implementation by executing the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_thetas = np.array([[0.0017878 ], [0.48483375]])\n",
    "actual_thetas = fit_reg(X_train, y_train, lam=2)\n",
    "\n",
    "np.testing.assert_array_almost_equal(expected_thetas, actual_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  plot the graph using the regularized parameter vectors. As you can see, the effect of overfitting is strongly reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5a18b9b4e3477290491f1d08039ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='poly_deg', max=12), IntSlider(value=4, description='lam'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(poly_deg = (0,12,1), lam=(0,100,1))\n",
    "def f(poly_deg=1, lam=4):\n",
    "    poly = PolynomialFeatures(poly_deg)\n",
    "    X_train_deg = poly.fit_transform(X_train[\"sqft_living\"].values.reshape(-1,1))\n",
    "    X_test_deg = poly.fit_transform(X_test[\"sqft_living\"].values.reshape(-1,1))\n",
    "\n",
    "    thetas_deg = fit_reg(X_train_deg, y_train, lam=lam)\n",
    "    \n",
    "    y_pred_test = predict(X_test_deg, thetas_deg)\n",
    "    y_pred_train = predict(X_train_deg, thetas_deg)\n",
    "    \n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    print(\"R2 Train\", r2_train)\n",
    "    print(\"R2 Test\", r2_test)\n",
    "    \n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(20,10))\n",
    "    ax0.set_title(\"Training data - polynomial degree {}\".format(poly_deg))\n",
    "    ax0.plot(X_train[\"sqft_living\"], y_train[\"price\"], \"bo\", markersize=1)\n",
    "    plot_regression_line(X_train_deg, thetas_deg, ax0)\n",
    "    \n",
    "    ax0.set_title(\"Test data - polynomial degree {}\".format(poly_deg))\n",
    "    ax1.plot(X_test[\"sqft_living\"], y_test[\"price\"], \"bo\", markersize=1)\n",
    "    plot_regression_line(X_test_deg, thetas_deg, ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best configuration of **polynomial degree** and $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>PLEASE REPLACE TEXT WITH YOUR CONFIGURATION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization to help with numerical issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another benefit of regularization is that it can help in case of numerical issues. Let us consider our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>2570</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>770</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>1960</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>1680</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  sqft_living  bedrooms\n",
       "0  221900.0         1180         3\n",
       "1  538000.0         2570         3\n",
       "2  180000.0          770         2\n",
       "3  604000.0         1960         4\n",
       "4  510000.0         1680         3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"kc_house_data.csv\")\n",
    "df = df[[\"price\",\"sqft_living\",\"bedrooms\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.038033</td>\n",
       "      <td>0.134340</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0.103607</td>\n",
       "      <td>0.196981</td>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>0.126295</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218</th>\n",
       "      <td>0.185574</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>0.083410</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  sqft_living  bedrooms\n",
       "735    0.038033     0.134340  0.121212\n",
       "2830   0.103607     0.196981  0.151515\n",
       "4106   0.126295     0.262642  0.121212\n",
       "16218  0.185574     0.322264  0.090909\n",
       "19964  0.083410     0.170566  0.090909"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns, index=train.index)\n",
    "test = pd.DataFrame(scaler.fit_transform(test), columns=test.columns, index=test.index)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the feature matrix $X^{\\top}X$ singular, we just add  another independent variable (Size2) to X\n",
    "that amounts to just twice the Size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>sqft_living2</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.038033</td>\n",
       "      <td>0.134340</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.268679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>0.103607</td>\n",
       "      <td>0.196981</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.393962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>0.126295</td>\n",
       "      <td>0.262642</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.525283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16218</th>\n",
       "      <td>0.185574</td>\n",
       "      <td>0.322264</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.644528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>0.083410</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.341132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  sqft_living  bedrooms  sqft_living2  bias\n",
       "735    0.038033     0.134340  0.121212      0.268679     1\n",
       "2830   0.103607     0.196981  0.151515      0.393962     1\n",
       "4106   0.126295     0.262642  0.121212      0.525283     1\n",
       "16218  0.185574     0.322264  0.090909      0.644528     1\n",
       "19964  0.083410     0.170566  0.090909      0.341132     1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"sqft_living2\"] = 2 * train[\"sqft_living\"]\n",
    "train[\"bias\"] = 1\n",
    "\n",
    "test[\"sqft_living2\"]=2 * test[\"sqft_living\"]\n",
    "test[\"bias\"] = 1\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"bias\", \"sqft_living\", \"bedrooms\", \"sqft_living2\"]]\n",
    "y_train = train[[\"price\"]]\n",
    "\n",
    "X_test = test[[\"bias\", \"sqft_living\", \"bedrooms\", \"sqft_living2\"]]\n",
    "y_test = test[[\"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the linear regression fails, since $X^{\\top}X$ is not invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-98bb011aa187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-dc0e934d0e04>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthetas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/HSLU_ML-myLqnJHJ/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/HSLU_ML-myLqnJHJ/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "thetas = fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two possiblities to tackle this issue, the first one is to use the pseudoinverse instead of the inverse\n",
    "and the second one is using regularization. \n",
    "\n",
    "> Try out both. \n",
    "\n",
    "*Hint*: For conducting linear regression with the pseudoinverse, you have to slightly modify the linear_regression method given further above. \n",
    "The numpy function [np.linalg.pinv](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html) becomes handy for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "def fit_pseudoinverse(X,y):\n",
    "    thetas = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "def fit_pseudoinverse(X, y):\n",
    "    thetas = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code to check your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetas obtained by linear regression with pseudoinverse:\n",
      " [[ 0.02902459]\n",
      " [ 0.11220321]\n",
      " [-0.12253607]\n",
      " [ 0.22440641]]\n"
     ]
    }
   ],
   "source": [
    "thetas_pseudo_inverse = fit_pseudoinverse(X_train, y_train)\n",
    "print (\"thetas obtained by linear regression with pseudoinverse:\\n\",thetas_pseudo_inverse)\n",
    "\n",
    "expected_thetas_pseudo_inverse = np.array([\n",
    "    [ 0.02902459],\n",
    "    [ 0.11220321],\n",
    "    [-0.12253607],\n",
    "    [ 0.22440641]])\n",
    "\n",
    "np.testing.assert_array_almost_equal(thetas_pseudo_inverse, expected_thetas_pseudo_inverse, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thetas obtained by linear regression with regularization:\n",
      " [[ 0.02842384]\n",
      " [ 0.11163472]\n",
      " [-0.11920766]\n",
      " [ 0.22326945]]\n"
     ]
    }
   ],
   "source": [
    "thetas_regularization = fit_reg(X_train, y_train,lam=1)\n",
    "print (\"thetas obtained by linear regression with regularization:\\n\",thetas_regularization)\n",
    "\n",
    "expected_thetas_regularization = np.array([\n",
    "    [ 0.02842384],\n",
    "    [ 0.11163472],\n",
    "    [-0.11920766],\n",
    "    [ 0.22326945]])\n",
    "\n",
    "np.testing.assert_array_almost_equal(thetas_regularization, expected_thetas_regularization, decimal=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regularization for Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us apply regularization to a larger dataset using sklearn, for which we reuse the eczema dataset from the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"skin_disease.csv\")\n",
    "df.drop('t0', axis=1, inplace=True)\n",
    "df.drop('t1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again split the data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[[\"class\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the data using the RobustScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Logistic Regression model\n",
    "> Train a Logistic Regression model by using the Scikit-Learn class [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). And calculate the accuracy and the f1 score on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.93277\n",
      "F1 Score 0.5706073960528837\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"F1 Score\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Accuracy\", accuracy)\n",
    "print(\"F1 Score\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularize our Logistic Regression model\n",
    "> For the logistic regression model we can also apply L2 regularization. Try systematically all L2 regularization parameters in the interval [0,2] with step size 0.1, a technique also known as grid search. Calculate for each iteration the accuracy and the f1 score.\n",
    "\n",
    "Hint: Take a look at the documentation of the [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class and specify the correct **regularization type** with the parameter **penalty**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0871e752673944d3b5975f783350f529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best accuracy: 0.9328 with C-value: 0.10\n",
      "Best f1_score: 0.5706 with C-value: 0.10\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "f1_scores = []\n",
    "C_values = np.arange(0.1, 2.1, 0.1)\n",
    "for c in tqdm(C_values):\n",
    "    # L2 is the default penalty\n",
    "    model = LogisticRegression().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "max_acc_idx = np.argmax(accuracies)\n",
    "print(\"Best accuracy: {0:.4f} with C-value: {1:.2f}\".format(accuracies[max_acc_idx], C_values[max_acc_idx]))\n",
    "print(\"Best f1_score: {0:.4f} with C-value: {1:.2f}\".format(f1_scores[max_acc_idx], C_values[max_acc_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_scores = []\n",
    "C_values = np.arange(0.1, 2.1, 0.1)\n",
    "for c in tqdm(C_values):\n",
    "    model = LogisticRegression(penalty=\"l2\", C=c)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "max_acc_idx = np.argmax(accuracies)\n",
    "print(\"Best accuracy: {0:.4f} with C-value: {1:.2f}\".format(accuracies[max_acc_idx], C_values[max_acc_idx]))\n",
    "print(\"Best f1_score: {0:.4f} with C-value: {1:.2f}\".format(f1_scores[max_acc_idx], C_values[max_acc_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid-Search with Scikit-Learn\n",
    "This can be also done directly with Scikit-Learn. The following cell performs a grid search using a 5-fold cross validation.\n",
    "\n",
    "<font color='red'>This can take a while!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l2\")\n",
    "params = {\n",
    "    'C': np.arange(0.1, 2.1, 0.1)\n",
    "}\n",
    "grid_search = GridSearchCV(model, params, cv=5, scoring=\"f1\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best params\", grid_search.best_params_)\n",
    "print(\"Best f1 score\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best C value is not the same as we got when we performed our grid search manually. The reason is that we did not use cross validation but tuned our hyperparameters on the test set. This should not be done because then we overfit our model on the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final remark, in this notebook we used for simplicity skin pixels from the same image for training and testing.\n",
    "In real world scenarios, the test and training data set should originate from different images, \n",
    "since skin pixels from the same image are highly correlated and your evaluation measure values would therefore \n",
    "probably be too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "> Now finish the ILIAS quiz to **Regularization**."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
